{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import jit, cuda, vectorize, float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 First testing numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov = np.random.randn(100).reshape((10, 10))\n",
    "vec = np.random.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.2643887216958039"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(vec, cov), vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.44 s ± 52.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def sum2d(M):\n",
    "    summation = 0.\n",
    "    for i in range(M):\n",
    "        for j in range(M):\n",
    "            summation += np.dot(np.dot(vec, cov), vec)\n",
    "    return summation\n",
    "%timeit sum2d(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.1 s ± 998 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def sum2d(M):\n",
    "    summation = 0.\n",
    "    for i in range(M):\n",
    "        for j in range(M):\n",
    "            summation += np.dot(np.dot(vec, cov), vec)\n",
    "    return summation\n",
    "%timeit sum2d(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Need NVIDIA gpu to run CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below runs on i7-7700K and NVIDIA TITAN Xp, a powerful GPU over a thousand dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0     b'GeForce RTX 2070'                              [SUPPORTED]\n",
      "                      compute capability: 7.5\n",
      "                           pci device id: 0\n",
      "                              pci bus id: 1\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numba.cuda.detect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Vectorize_add\n",
    "### It seems that target=cpu is better than target=cuda. Unexpected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize([float64(float64,float64)], target='cuda')\n",
    "def add_vec_cuda(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize([float64(float64, float64)], target='cpu')\n",
    "def add_vec_cpu(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def add_jit(X, Y):\n",
    "    size = len(X)\n",
    "    Z = []\n",
    "    for i in range(size):\n",
    "        Z.append(X[i] + Y[i])\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 ms ± 272 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "27.2 µs ± 142 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "2.32 ms ± 115 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(100000, dtype=np.float64)\n",
    "%timeit add_vec_cuda(a, a)\n",
    "%timeit add_vec_cpu(a, a)\n",
    "%timeit add_jit(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.62 ms ± 25.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "644 µs ± 9.42 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "28.4 ms ± 183 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1000000, dtype=np.float64)\n",
    "%timeit add_vec_cuda(a, a)\n",
    "%timeit add_vec_cpu(a, a)\n",
    "%timeit add_jit(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 ms ± 985 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "25.4 ms ± 228 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "344 ms ± 658 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10000000, dtype=np.float64)\n",
    "%timeit add_vec_cuda(a, a)\n",
    "%timeit add_vec_cpu(a, a)\n",
    "%timeit add_jit(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549 ms ± 15.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "256 ms ± 1.36 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.39 s ± 9.54 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(100000000, dtype=np.float64)\n",
    "%timeit add_vec_cuda(a, a)\n",
    "%timeit add_vec_cpu(a, a)\n",
    "%timeit add_jit(a, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Vectorize_sincos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "x = np.arange(n, dtype=np.float64)\n",
    "y = np.arange(n, dtype=np.float64)\n",
    "\n",
    "np_ans = np.sin(x) * np.cos(y)\n",
    "nb_cpu_ans = cpu_sincos(x, y)\n",
    "nb_gpu_ans = gpu_sincos(x, y)\n",
    "\n",
    "print(\"CPU vectorize:\", np.allclose(nb_cpu_ans, np_ans))\n",
    "print(\"CPU vectorize:\", np.allclose(nb_gpu_ans, np_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.45464871, -0.37840125, ..., -0.20931808,\n",
       "        0.49999812, -0.2068272 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.45464871, -0.37840125, ..., -0.20931808,\n",
       "        0.49999812, -0.2068272 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def my_kernal(io_array):\n",
    "    pos = cuda.grid(1)\n",
    "    if pos < io_array.size: # check array boundaries\n",
    "        io_array[pos] *= 2  # do the computation\n",
    "        \n",
    "data = np.ones(500000000)\n",
    "threadsperblock = 256\n",
    "blockspergrid = math.ceil(data.shape[0]/threadsperblock)\n",
    "print(blockspergrid)\n",
    "my_kernal[blockspergrid, threadsperblock](data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    row, col = cuda.grid(2)\n",
    "    #print(row, col)\n",
    "    if row < C.shape[0] and col < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[row, k] * B[k, col]\n",
    "        C[row, col] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def host_code():\n",
    "    A = np.full((24, 12), 3, np.float)\n",
    "    B = np.full((12, 6), 4, np.float)\n",
    "    #copy the arrays to the device\n",
    "    A_global_mem = cuda.to_device(A)\n",
    "    B_global_mem = cuda.to_device(B)\n",
    "    \n",
    "    #allocate memory on the device for the result\n",
    "    C_global_mem = cuda.device_array((24, 6))\n",
    "    \n",
    "    # configure the blocks\n",
    "    threadsperblock = (16, 16)\n",
    "    blockspergrid_x = int(math.ceil(A.shape[0] / threadsperblock[0]))\n",
    "    blockspergrid_y = int(math.ceil(B.shape[1] / threadsperblock[1]))\n",
    "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "    print(blockspergrid)\n",
    "    \n",
    "    #start the kernal\n",
    "    matmul[blockspergrid, threadsperblock](A_global_mem, B_global_mem, C_global_mem)\n",
    "    \n",
    "    C = C_global_mem.copy_to_host()\n",
    "    print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "[[144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144.]]\n"
     ]
    }
   ],
   "source": [
    "host_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the computation will be done on blocks of TPB*TPB elements\n",
    "TPB = 16\n",
    "\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    '''matrix multiplication C = A*B\n",
    "       each thread computes one element of the result matrix C\n",
    "    '''\n",
    "    # define an array in the shared memory\n",
    "    # the size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float64)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float64)\n",
    "    \n",
    "    x, y = cuda.grid(2)\n",
    "    \n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    if x >= C.shape[0] or y >= C.shape[1]:\n",
    "        return\n",
    "    \n",
    "    # each thread computes one element in the result matrix\n",
    "    # the dot product is chunked into dot products of TPB-long vectors\n",
    "    tmp = 0\n",
    "    for i in range(int(A.shape[1]/TPB)):\n",
    "        # preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i*TPB]\n",
    "        sB[tx, ty] = B[tx + i*TPB, y]\n",
    "        \n",
    "        # wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "        \n",
    "        # computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j]*sB[j, ty]\n",
    "        \n",
    "        # wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "    \n",
    "    C[x, y] = tmp\n",
    "    \n",
    "    \n",
    "def host_code():\n",
    "    # initialize the data arrays\n",
    "    A = np.full((TPB*2, TPB*3), 3, np.float64)  # [32 x 48] matrix containing all 3's\n",
    "    B = np.full((TPB*3, TPB*1), 4, np.float64)  # [48 x 16] matrix containing all 4's\n",
    "    \n",
    "    A_global_mem = cuda.to_device(A)\n",
    "    B_global_mem = cuda.to_device(B)\n",
    "    C_global_mem = cuda.device_array((TPB*2, TPB*1))  # [32 x 16] matrix result\n",
    "    \n",
    "    # configure the blocks\n",
    "    threadsperblock = (TPB, TPB)\n",
    "    blockspergrid_x = int(math.ceil(A.shape[0] / threadsperblock[1]))\n",
    "    blockspergrid_y = int(math.ceil(B.shape[1] / threadsperblock[0]))\n",
    "    blockspergrid   = (blockspergrid_x, blockspergrid_y)\n",
    "    \n",
    "    # start the kernal\n",
    "    fast_matmul[blockspergrid, threadsperblock](A_global_mem, B_global_mem, C_global_mem)\n",
    "    \n",
    "    res = C_global_mem.copy_to_host()\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]\n",
      " [576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576. 576.\n",
      "  576. 576.]]\n"
     ]
    }
   ],
   "source": [
    "host_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gpu = numba.cuda.get_current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: b'TITAN Xp'\n",
      "Compute capability: 6.1\n",
      "Number of streaming multiprocessor: 30\n",
      "Warp size: 32\n"
     ]
    }
   ],
   "source": [
    "print('Running on GPU:', my_gpu.name)\n",
    "cc = my_gpu.compute_capability\n",
    "print('Compute capability:', '%d.%d' % cc)\n",
    "majorcc = cc[0]\n",
    "print('Number of streaming multiprocessor:', my_gpu.MULTIPROCESSOR_COUNT)\n",
    "print('Warp size:', my_gpu.WARP_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: b'GeForce RTX 2070'\n"
     ]
    }
   ],
   "source": [
    "my_gpu = numba.cuda.get_current_device()\n",
    "print('Running on GPU:', my_gpu.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.reduce\n",
    "def sum_reduce(a, b):\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.reduce\n",
    "def prod_reduce(a, b):\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49520229, 0.31728205, 0.64370056, 0.83666699, 0.99212089,\n",
       "       0.57449774, 0.19645054, 0.21741065, 0.34823381, 0.05249949,\n",
       "       0.15167274, 0.30539631, 0.89892828, 0.84619581, 0.1263457 ,\n",
       "       0.09248628, 0.19729178, 0.27399845, 0.57263513, 0.94340047,\n",
       "       0.02307522, 0.96050561, 0.88203672, 0.9509195 , 0.22195873,\n",
       "       0.45213043, 0.23821942, 0.8361377 , 0.84913675, 0.31234116,\n",
       "       0.8697915 , 0.92518473, 0.93258319, 0.64598185, 0.29489136,\n",
       "       0.81203368, 0.69054997, 0.99351217, 0.69977451, 0.5569984 ,\n",
       "       0.42456272, 0.13792686, 0.95898616, 0.14801117, 0.2009087 ,\n",
       "       0.00926096, 0.17103223, 0.43875822, 0.79719821, 0.28175292,\n",
       "       0.5432386 , 0.27899108, 0.94970595, 0.42730572, 0.97053749,\n",
       "       0.59699898, 0.9161051 , 0.57965538, 0.51550952, 0.279398  ,\n",
       "       0.84859616, 0.47921384, 0.75759376, 0.06642723, 0.64898679,\n",
       "       0.96136056, 0.00151634, 0.85748513, 0.61899598, 0.50925678,\n",
       "       0.96362942, 0.69421166, 0.94616359, 0.24679265, 0.79914761,\n",
       "       0.73224336, 0.25343806, 0.98186431, 0.476126  , 0.99078407,\n",
       "       0.99827053, 0.36736808, 0.41011761, 0.66529723, 0.92771136,\n",
       "       0.92939245, 0.27767513, 0.25308543, 0.33397974, 0.61605232,\n",
       "       0.95579307, 0.33337847, 0.55760391, 0.44305001, 0.7040543 ,\n",
       "       0.48410289, 0.7011232 , 0.07461691, 0.48467883, 0.0886957 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.rand(100)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.29590298978487"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_A = cuda.to_device(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.29590298978487"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_reduce(d_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 µs ± 3.11 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625 µs ± 6.95 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum_reduce(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379 µs ± 4.15 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum_reduce(d_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.160509257746661e-39"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_reduce(d_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3276801280000.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_reduce(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
